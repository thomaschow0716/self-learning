{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "088b1e09-3257-4761-ab8b-72bde741bd9d",
   "metadata": {},
   "source": [
    "Bag of Words\n",
    "- convert sentences to vectors\n",
    "- Extract all the unique words from sentences\n",
    "- binary = 0 and 1s , could also be count of words\n",
    "- unigram = take individual word, bigram = 2 words\n",
    "- Limitation: words not in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b193b616-0a17-49d8-a04c-420952644ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "    BOOKS = 'BOOKS'\n",
    "    CLOTHING = 'CLOTHING'\n",
    "\n",
    "train_x = ['i love the book', 'this is a great book', 'the fit is great', 'i love the shoes']\n",
    "train_y = [Category.BOOKS, Category.BOOKS, Category.CLOTHING, Category.CLOTHING]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87922be2-21fe-4e3a-be69-3483cf7959b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['book' 'fit' 'great' 'is' 'love' 'shoes' 'the' 'this']\n",
      "[[1 0 0 0 1 0 1 0]\n",
      " [1 0 1 1 0 0 0 1]\n",
      " [0 1 1 1 0 0 1 0]\n",
      " [0 0 0 0 1 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# binary for 0s and 1s\n",
    "# ngram_range for unigram, bigram\n",
    "vectorizer = CountVectorizer(binary = True)\n",
    "train_x_vectors = vectorizer.fit_transform(train_x)\n",
    "\n",
    "print(vectorizer.get_feature_names_out())\n",
    "# stripped away 'a', 'i'\n",
    "print(train_x_vectors.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5084d0e8-be53-4bb6-b8b9-d5b9b36d5f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "clf_svm = svm.SVC(kernel = 'linear')\n",
    "clf_svm.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a2198e45-a978-437b-b490-d3d8bdfba3fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CLOTHING'], dtype='<U8')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = vectorizer.transform(['shoes are alright'])\n",
    "clf_svm.predict(test_x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c37f6aa-ff2a-4ff9-a9db-346524c14c83",
   "metadata": {},
   "source": [
    "Word Vectors\n",
    "- capture semantic meaning of words\n",
    "- map similar words to similar vector space\n",
    "- use a window of text as context window, use surrounding token to find meaning of individual token\n",
    "- e.g. book and read, story and characters\n",
    "- uses neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "410f807b-c348-4642-a206-8f4b533ba0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medium model\n",
    "# !python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "937c4f80-f7f4-44a5-ac05-586332b6806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# word embedding\n",
    "nlp = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80a2dcbe-58f3-4fad-99cb-d68b181044d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i love the book', 'this is a great book', 'the fit is great', 'i love the shoes']\n"
     ]
    }
   ],
   "source": [
    "print(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "505c1ff9-de30-442b-b9b9-c95e50b91382",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [nlp(text) for text in train_x]\n",
    "# i love the book\n",
    "# print(docs[0].vector)\n",
    "train_x_word_vectors = [x.vector for x in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a5e20f60-a3e9-486f-a6ee-5843706061ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_svm_wv = svm.SVC(kernel = 'linear')\n",
    "clf_svm_wv.fit(train_x_word_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbda3fc6-7b1d-4f19-b049-48d79737ffa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CLOTHING'], dtype='<U8')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = ['these earings hurt']\n",
    "# npl() = average embedding\n",
    "# words with multiple meaning may be problematic\n",
    "test_docs = [nlp(text) for text in test_x]\n",
    "test_x_word_vectors = [x.vector for x in test_docs]\n",
    "\n",
    "clf_svm_wv.predict(test_x_word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13b2d9b6-d5ca-44e6-979a-32a15137cdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[these earings hurt]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958e4c2f-4615-4287-95ce-f89a6df06cb7",
   "metadata": {},
   "source": [
    "Regexes\n",
    "\n",
    "- pattern matching of strings\n",
    "- e.g. password, emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2209919-5f0d-446f-8a61-f3e83ce473b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abcd', 'abxxxcd']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "regexp = re.compile(r'^ab[^\\s]*cd$')\n",
    "\n",
    "phrases = ['abcd', 'xxx', 'abxxxcd', 'ab cd']\n",
    "\n",
    "matches = []\n",
    "for phrase in phrases:\n",
    "    # re.search for any place in the string\n",
    "    if re.match(regexp, phrase):\n",
    "        matches.append(phrase)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "353df0cc-247d-4599-9767-32b0fb0777d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# \\b\\b for words by itself\n",
    "regexp = re.compile(r'\\bread\\b|\\bstory\\b|book')\n",
    "\n",
    "phrases = ['I like that history', 'the car treaded up the hill', 'this hat is nice']\n",
    "\n",
    "matches = []\n",
    "for phrase in phrases:\n",
    "    if re.search(regexp, phrase):\n",
    "        matches.append(phrase)\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923c70e8-ca57-417a-831e-4c9d2396f3fd",
   "metadata": {},
   "source": [
    "Stemming/Lemmatization\n",
    "\n",
    "- normalize text\n",
    "- stories -> stori(stemming), stories -> story (lemmatization, actual english words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c792badc-fd0c-479c-84a1-46535cc11751",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\thoma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5500827e-c530-4330-a3af-ff2152e834ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read the book'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# strip punctuation first\n",
    "phrase = 'reading the books'\n",
    "words = word_tokenize(phrase)\n",
    "\n",
    "stemmed_words = []\n",
    "for word in words:\n",
    "    stemmed_words.append(stemmer.stem(word))\n",
    "\n",
    "' '.join(stemmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cce1947-5af1-4c78-9690-7f2d1974f5ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read the book'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "phrase = 'reading the books'\n",
    "words = word_tokenize(phrase)\n",
    "\n",
    "lemmatized_words = []\n",
    "for word in words:\n",
    "    # pos = verbs\n",
    "    # may need part of speech tag to identify the nature of the words\n",
    "    lemmatized_words.append(lemmatizer.lemmatize(word, pos = 'v'))\n",
    "\n",
    "' '.join(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e2e74b-e522-4111-a9b3-a4847bb767d1",
   "metadata": {},
   "source": [
    "Stopwords\n",
    "\n",
    "- most common english words\n",
    "- strip out as no additional value, e.g. the, this, that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a4356320-8c57-4896-8a12-8c6ac73e6bb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here example sentence demonstrating removal stopwords'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "phrase = 'Here is an example sentence demonstrating the removal of stopwords'\n",
    "\n",
    "words = word_tokenize(phrase)\n",
    "\n",
    "stripped_phrase = []\n",
    "for word in words:\n",
    "    if word not in stop_words:\n",
    "        stripped_phrase.append(word)\n",
    "        \n",
    "' '.join(stripped_phrase)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "042cca1c-3253-43be-9b85-4e4e21e9a041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-1.0, subjectivity=1.0)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Spell Correction\n",
    "from textblob import TextBlob\n",
    "\n",
    "phrase = 'the bok was horrible'\n",
    "\n",
    "tb_phrase = TextBlob(phrase)\n",
    "\n",
    "tb_phrase.correct()\n",
    "\n",
    "\n",
    "# Part of speech tagging\n",
    "# identify noun, verbs, ...\n",
    "tb_phrase.tags\n",
    "\n",
    "# polarity = positive/negative sentiment\n",
    "tb_phrase.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e514d2db-c3da-4031-9ca6-07341265603b",
   "metadata": {},
   "source": [
    "Transformer architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0efa975b-d779-45f5-9517-c0dafd35d542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT model\n",
    "import spacy\n",
    "import torch\n",
    "import spacy_transformers\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "doc = nlp('Here is some text to encode.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fde6be2f-bdd3-459c-a2ff-4d957fa61220",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category:\n",
    "    BOOKS = 'BOOKS'\n",
    "    BANK = 'BANK'\n",
    "\n",
    "train_x = [\"good characters and plot progression\", 'check out the book', 'good story. would recommend', 'novel recommendation', 'need to make a deposit to the bank', 'balance inquiry savings', 'save money']\n",
    "train_y = [Category.BOOKS, Category.BOOKS, Category.BOOKS, Category.BOOKS, Category.BANK, Category.BANK, Category.BANK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c5cf4e8a-91a2-445f-bf32-ae73cdd9df3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['BANK'], dtype='<U5')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs = [nlp(text) for text in train_x]\n",
    "train_x_vectors = [doc.vector for doc in docs]\n",
    "\n",
    "clf_svm.fit(train_x_vectors, train_y)\n",
    "\n",
    "# classified as bank even though no mention in training set\n",
    "test_x = ['i need to write a check']\n",
    "docs = [nlp(text) for text in test_x]\n",
    "test_x_vectors = [doc.vector for doc in docs]\n",
    "\n",
    "clf_svm.predict(test_x_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
